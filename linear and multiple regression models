Steps to Implement Linear and Multiple Regression Models:
Import Libraries
Load and Explore the Boston Dataset
Preprocess the Data
Build the Linear Regression Model
Build the Multiple Regression Model
Evaluate Model Performance
Make Predictions Using the Models
1. Import Libraries
python
Copy code
import numpy as np
import pandas as pd
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
Note: The load_boston dataset from sklearn.datasets has been deprecated. We’ll use an equivalent dataset for demonstration or if you have a CSV file with similar data, that can be used.

For this example, we will load the data from a CSV file (you can replace it with your own dataset if needed).

python
Copy code
# Load the Boston dataset (assuming it's in a CSV file)
# df = pd.read_csv('boston_house_prices.csv')

# Load the dataset using sklearn's load_boston for demonstration
boston = load_boston()
df = pd.DataFrame(boston.data, columns=boston.feature_names)
df['PRICE'] = boston.target

# Display the first few rows of the dataset
print(df.head())
2. Explore the Dataset
Exploring the data to get an idea of the feature columns and the target column (PRICE).

python
Copy code
# Check for null values
print(df.isnull().sum())

# Describe the dataset
print(df.describe())
3. Preprocess the Data
We'll split the dataset into features (independent variables) and the target variable (dependent variable).

python
Copy code
# Define features (X) and target (y)
X = df.drop(columns='PRICE')  # Features: all columns except 'PRICE'
y = df['PRICE']  # Target: 'PRICE'

# Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
4. Build the Linear Regression Model
We will build a simple linear regression model using one feature to predict the price of houses. Let’s choose the RM (number of rooms) feature as a predictor.

python
Copy code
# Choose a single feature (RM) for linear regression
X_single = df[['RM']]

# Split the data
X_train_single, X_test_single, y_train_single, y_test_single = train_test_split(X_single, y, test_size=0.2, random_state=42)

# Initialize and train the Linear Regression model
lin_reg_single = LinearRegression()
lin_reg_single.fit(X_train_single, y_train_single)

# Make predictions on the test set
y_pred_single = lin_reg_single.predict(X_test_single)

# Evaluate the model
mse_single = mean_squared_error(y_test_single, y_pred_single)
r2_single = r2_score(y_test_single, y_pred_single)

print(f"Linear Regression (Single Feature RM) - MSE: {mse_single:.2f}, R²: {r2_single:.2f}")

# Visualize the results
plt.scatter(X_test_single, y_test_single, color='blue')
plt.plot(X_test_single, y_pred_single, color='red')
plt.title('Linear Regression: RM vs Price')
plt.xlabel('Number of Rooms (RM)')
plt.ylabel('House Price')
plt.show()
5. Build the Multiple Regression Model
For multiple regression, we'll use all available features in the dataset to predict house prices.

python
Copy code
# Initialize and train the Multiple Linear Regression model
multi_reg = LinearRegression()
multi_reg.fit(X_train, y_train)

# Make predictions on the test set
y_pred_multi = multi_reg.predict(X_test)

# Evaluate the model
mse_multi = mean_squared_error(y_test, y_pred_multi)
r2_multi = r2_score(y_test, y_pred_multi)

print(f"Multiple Regression (All Features) - MSE: {mse_multi:.2f}, R²: {r2_multi:.2f}")
6. Evaluate Model Performance
For both linear and multiple regression, we evaluate the models based on Mean Squared Error (MSE) and R-squared (R²) score.

7. Make Predictions Using the Models
Now, let’s predict house prices using the trained models for new data points.

python
Copy code
# Predict house price for a house with 6 rooms using linear regression
rm_value = np.array([[6]])
predicted_price_single = lin_reg_single.predict(rm_value)
print(f"Predicted house price for 6 rooms: ${predicted_price_single[0]:.2f}")

# Predict house price for a sample using multiple regression
sample_features = np.array([[0.00632, 18.0, 2.31, 0.0, 0.538, 6.575, 65.2, 4.09, 1.0, 296.0, 15.3, 396.9, 4.98]])
predicted_price_multi = multi_reg.predict(sample_features)
print(f"Predicted house price for the given features: ${predicted_price_multi[0]:.2f}")
Full Code Implementation:
python
Copy code
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import load_boston

# Load Boston dataset
boston = load_boston()
df = pd.DataFrame(boston.data, columns=boston.feature_names)
df['PRICE'] = boston.target

# Split the dataset into features (X) and target (y)
X = df.drop(columns='PRICE')
y = df['PRICE']

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Linear Regression with one feature (RM)
X_single = df[['RM']]
X_train_single, X_test_single, y_train_single, y_test_single = train_test_split(X_single, y, test_size=0.2, random_state=42)

# Initialize and train the model
lin_reg_single = LinearRegression()
lin_reg_single.fit(X_train_single, y_train_single)

# Predict on test data
y_pred_single = lin_reg_single.predict(X_test_single)

# Evaluate the model
mse_single = mean_squared_error(y_test_single, y_pred_single)
r2_single = r2_score(y_test_single, y_pred_single)
print(f"Linear Regression (RM) - MSE: {mse_single:.2f}, R²: {r2_single:.2f}")

# Visualize linear regression results
plt.scatter(X_test_single, y_test_single, color='blue')
plt.plot(X_test_single, y_pred_single, color='red')
plt.title('Linear Regression: RM vs Price')
plt.xlabel('Number of Rooms (RM)')
plt.ylabel('House Price')
plt.show()

# Multiple Regression with all features
multi_reg = LinearRegression()
multi_reg.fit(X_train, y_train)

# Predict on test data
y_pred_multi = multi_reg.predict(X_test)

# Evaluate the model
mse_multi = mean_squared_error(y_test, y_pred_multi)
r2_multi = r2_score(y_test, y_pred_multi)
print(f"Multiple Regression - MSE: {mse_multi:.2f}, R²: {r2_multi:.2f}")

# Predict house price for 6 rooms
rm_value = np.array([[6]])
predicted_price_single = lin_reg_single.predict(rm_value)
print(f"Predicted house price for 6 rooms: ${predicted_price_single[0]:.2f}")

# Predict house price for a given set of features
sample_features = np.array([[0.00632, 18.0, 2.31, 0.0, 0.538, 6.575, 65.2, 4.09, 1.0, 296.0, 15.3, 396.9, 4.98]])
predicted_price_multi = multi_reg.predict(sample_features)
print(f"Predicted house price for the given features: ${predicted_price_multi[0]:.2f}")
Conclusion:
Linear Regression was built using a single feature (number of rooms) to predict house prices.
Multiple Regression was built using all features in the dataset to predict house prices.
Both models were evaluated based on MSE and R-squared scores.
Predictions were made for new data points using the trained models.










